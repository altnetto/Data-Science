{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Método K-Vizinhos</h3>\n",
    "\n",
    "- Calcula as distâncias para uma vizinhança próxima\n",
    "- Tais cálculos podem ser utilizando:\n",
    "    - Distância euclidiana\n",
    "    - Minkowski (uma variação para p-dimensões da distância euclidiana)\n",
    "    - Cosseno\n",
    "    - Pearson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Algoritmo K-Vizinhos</h3>\n",
    "\n",
    "- Identifique os k-vizinhos mais próximos do vetor de atributos X que se quer classificar\n",
    "- Determine o número de vizinhos em cada classe\n",
    "- Classifique X como pertencente à classe que resultou em um maior número de vizinhos (a moda entre o número de classes)\n",
    "- Regiões de separação formam as telhas de Voronoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Como funciona?</h3>\n",
    "\n",
    "- Calcula-se a distância do item desejado (\\*) até todos os elementos disponíveis d(\\*, objetos)\n",
    "- A partir da definição de K, será escolhida a classe com base na moda dos resultados\n",
    "- Ex: no caso de duas classes, com K = 3, onde d1 é da classe A, d2 da classe B e d3 também da classe B, teremos que d\\* pertence à classe B, mesmo que d1 esteja mais próximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Selecionando K</h3>\n",
    "\n",
    "Na escolha de K, como em qualquer análise relacionada a dados, a escolha dos hiperparâmetros (parâmetros que só dependem do usuário) serão a diferença entre acertar e errar.\n",
    "\n",
    "- K muito pequeno, pode gerar **Overfitting**\n",
    "\n",
    "- K muito grande, pode gerar **Underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Propriedades do KNN</h3>\n",
    "\n",
    "- Algoritmo não é de aprendizado, apenas de memorização dos objetos de treinamento\n",
    "- Bom para classificação (adia a fase computacional para a classificação)\n",
    "- Algoritmo pode ser não paramétrico, dependendo apenas do númeto de vizinhos (k)\n",
    "- É um classificador não-linear, não sendo restrito a regiões de separação lineares\n",
    "- Geralmente usa-se a distância Euclidiana\n",
    "    - Faz-se necessário normalizar ou padronizar os dados\n",
    "        - Caso contrário, teremos dominância de certas classes nos valores\n",
    "\n",
    "- Caso o conjunto de treino seja suficientemente grande, pode-se provar que o erro cometido na classificação é, no máximo, duas vezes maior que o classificador Bayesiano (**Naive Bayes**), que é ótimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regressão Logística</h3>\n",
    "\n",
    "- Trata-se de estimar a máxima verossimilhança (\\beta mais alto revela a classe)\n",
    "- Para facilitar a compreensão da regressão logística, geralmente se define em duas possíveis classes, ou seja, há a probabilidade de pertencer ou não ao conjunto (análise binária)\n",
    "- P(y = 1 |x) e P(y = 0 |x)\n",
    "- A região de separação dos dois conjuntos se dá por um hiperplano, onde temos P(y = 1 |x) = P(y = 0 |x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes</h3>\n",
    "\n",
    "- Se trata do método mais interessante, ao meu ver, pois é extremamente analítico e coerente.\n",
    "\n",
    "- Define-se as probabilidades de cada evento ocorrer, de modo que cada classe é independente da outra.\n",
    "\n",
    "- Após isso, faz-se um produtório das probabilidades e calcula-se qual é o maior valor.\n",
    "\n",
    "- Desse modo, o maior valor de produtório é a classe a ser selecionada\n",
    "\n",
    "- Isso nos gera o menor **erro** possível, o que é extremamente vantajoso em termos de análise de cenários\n",
    "    - Isso é similar ao que ocorre no processo de lógica de fuzzy\n",
    "    \n",
    "- P(X|Y) = P(X|Y)/P(Y) = P(X)\n",
    "*** P(X,Y) = P(X).P(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
