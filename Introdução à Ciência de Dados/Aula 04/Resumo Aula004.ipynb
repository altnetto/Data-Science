{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "55421908667a225820f2cd05496734e43c3ddbc7d792b945edc730d5b93ba56f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h3>Agrupamento de Dados</h3>\n",
    "\n",
    "Definindo similaridade entre objetos\n",
    "\n",
    "- Grau de Similaridade: $d(Xi,Xj)$ é máxima\n",
    "    - Ex: quanto mais amigos em uma rede social, mais fácil das pessoas serem próximas\n",
    "\n",
    "- Grau de Dissimilaridade: $d(Xi,Xj)$ é mínima\n",
    "    - Ex: quanto mais próximas duas cidades, a distância tende a zero (distância Euclidiana)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Equações de Agrupamento para dados Quantitativos</h3>\n",
    "\n",
    "- Grau de dissimilaridade:\n",
    "    - Distância Euclidiana: D = sqrt(sum((x-y)^2)) -> [0,+inf)\n",
    "    - Distância de Mincowski: D = (sum(abs((x-y))^p))^(1/p) -> [0,+inf)\n",
    "\n",
    "- Grau de similaridade:\n",
    "    - Cosseno: D = sum(x*y)/(sqrt(sum(x^2))*sqrt(sum(y^2))) -> \\[0,1\\]\n",
    "    - Pearson: D = sum((x-mean(x))*(y-mean(y)))/(sqrt(sum((x-mean(x))^2))*sqrt(sum((y-mean(y))^2))) -> \\[-1,1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Métricas de Distância</h3>\n",
    "\n",
    "- Dados Nominais\n",
    "    - Similaridade: s = 1 if p == q else s = 0\n",
    "    - Dissimilaridade: s = 0 if p == q else s = 1\n",
    "\n",
    "- Dados Ordinais\n",
    "    - Similaridade: s = 1 - abs(p - q)/(n - 1)\n",
    "    - Dissimilaridade: s = abs(p - q)/(n - 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Tipos de Agrupamentos de Dados</h3>\n",
    "\n",
    "- Particionamento em Clusters\n",
    "    - A // B // C\n",
    "\n",
    "- Particionamento em Clusters Hierárquico\n",
    "    - C : B : A\n",
    "    - Gera n subdivisões em Dendogramas (árvore de herança)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Representações dos grupos</h3>\n",
    "\n",
    "- Hiperplanos\n",
    "- Conjuntos\n",
    "- Matriz de probabilidades\n",
    "- Dendograma (árvore de herança)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Etapas do Agrupamento de Dados</h3>\n",
    "\n",
    "- Seleção de Atributos\n",
    "\n",
    "- Medida de Proximidade\n",
    "\n",
    "- Critério de clusterização\n",
    "\n",
    "- Algoritmo de clusterização\n",
    "\n",
    "- Validação dos Resultados\n",
    "\n",
    "- Interpretação dos Resultados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Método K-Means</h3>\n",
    "\n",
    "- Simples\n",
    "\n",
    "- Fácil de Interpretar\n",
    "\n",
    "- Eficiência Computacional\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Aplicando K-Means</h3>\n",
    "\n",
    "- Selecione k pontos como centroides iniciais\n",
    "\n",
    "- Iterar até que os centroides não mudem\n",
    "    - Associar os pontos dos k-grupos ao centroide mais próximo (geralmente distância euclidiana)\n",
    "        - Que tal usar lógica de Fuzzy?\n",
    "    - Calcule o centroide de cada grupo obtido\n",
    "\n",
    "*** Método da massa de pão (dividir em n massas de pão, com tamanhos variáveis)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Inicilização do K-Means</h3>\n",
    "\n",
    "- Algoritmo sensível à posição inicial das sementes\n",
    "\n",
    "- Importante rodar o algoritmo várias vezes para obter resultados consistentes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Elbow Method</h3>\n",
    "\n",
    "- Analisa o melhor valor de k, calculando a distância média dos pontos dentro de um cluster até o seu centróide\n",
    "- Within-Cluster Sum of Squares (WSS)\n",
    "- WCSS pode ser entendida como uma medida de compactação\n",
    "- O melhor número de clusters é dado na 'curva do cotovelo', quando há uma mudança brusca no valor do WCSS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Problemas do K-Means</h3>\n",
    "\n",
    "- Bastante sensível a clusters de diferentes tamanhos\n",
    "\n",
    "- Bastante sensível a clusters de diferentes densidades\n",
    "\n",
    "- Susceptível a problemas onde há clusters de diferentes formatos (geralmente não globulares)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>K-Means usando clusters Não Globulares</h3>\n",
    "\n",
    "- Deve-se usar o WCSS simple (mínimas distâncias entre clusters)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Agrupamento Hierárquico</h3>\n",
    "\n",
    "- Verifica-se a distância entre todos os pontos de um dado conjunto\n",
    "    - Ex: X = \\[(1,2),(1,5),(4,8),...\\]\n",
    "        - Faz-se D(X\\[0\\],X\\[1\\]), D(X\\[0\\],X\\[2\\]),..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "D45 1.41\nD12 2.0\nD23 2.0\nD46 2.0\nD14 2.24\nD16 2.24\nD24 2.24\nD13 2.83\nD25 3.0\nD01 3.16\nD56 3.16\nD06 3.61\nD15 3.61\nD26 3.61\nD34 4.12\nD04 5.0\nD35 5.0\nD36 5.0\nD02 5.1\nD03 5.1\nD05 6.4\n"
     ]
    }
   ],
   "source": [
    "X = [(3,2),(4,5),(4,7),(2,7),(6,6),(7,7),(6,4)]\n",
    "\n",
    "Dist = {}\n",
    "\n",
    "for i in X:\n",
    "    for j in X:\n",
    "\n",
    "        if X.index(i) == X.index(j) or X.index(j) < X.index(i):\n",
    "            continue\n",
    "\n",
    "        dist = round(( ((i[0]-j[0])**2) + ((i[1]-j[1])**2) )**(0.5),2)\n",
    "        Dist['D{0}{1}'.format(X.index(i),X.index(j))] = dist\n",
    "\n",
    "for item in sorted(Dist, key = Dist.get):\n",
    "    print(item,Dist[item])"
   ]
  },
  {
   "source": [
    "<h3>Agrupamento Hierárquico - Distância entre Clusters</h3>\n",
    "\n",
    "Métodos:\n",
    "\n",
    "- Mínima distância (single linkage)\n",
    "\n",
    "- Máxima distância (complete linkage)\n",
    "\n",
    "- Média dos grupos\n",
    "\n",
    "- Distância entre centroides\n",
    "\n",
    "- Outros métodos que usam uma função objetivo\n",
    "\n",
    "- Método de Ward, usa o erro quadrático médio -> geralmente o melhor método\n",
    "    - $d(C_i,C_j) = SS_{ij} - (SS_i + SS_j)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Avaliando Agrupamentos</h3>\n",
    "\n",
    "- Índice Externo\n",
    "    - Rótulos dos objetos conhecidos\n",
    "    - Queremos avaliar se os cluesters correspondem aos grupos originais\n",
    "    - Ex: Medidas de Entropia\n",
    "\n",
    "- Índice Interno\n",
    "    - Usado para avaliar um agrupamento sem usar informações externas\n",
    "    - Ex: soma do erro quadrático\n",
    "\n",
    "- Índice relativo\n",
    "    - Usado para comparar agrupamentos ou grupos\n",
    "    - Ex: índices internos ou externos são usados para esse fim\n",
    "\n",
    "- Matriz de similaridade\n",
    "    - Inspeção visual após o agrupamento"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Pureza</h3>\n",
    "\n",
    "- mede o quão puro é cada cluster (0~1)\n",
    "\n",
    "- Utiliza o maior valor no intervalo, dividido pelo número de elementos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f415723d7a0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m201\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# create blobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "np.random.seed(201)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# create blobs\n",
    "c = [(-2,1),(0,0),(4,6),(5,1),(6,12)]\n",
    "n=300\n",
    "data = make_blobs(n_samples=n, n_features=2, centers=c, cluster_std=1, random_state=50)\n",
    "X = data[0]\n",
    "labels = data[1]\n",
    "plt.scatter(X[:,0], X[:,1], c=labels, cmap='viridis', s=50, alpha=0.9)\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}